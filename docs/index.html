<!doctype html>
<html lang="en">

<!-- === Header Starts === -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Learning to Simulate Self-driven Particles System with Coordinated Policy Optimization</title>
    <link href="./assets/bootstrap.min.css" rel="stylesheet">
    <link href="./assets/font.css" rel="stylesheet" type="text/css">
    <link href="./assets/style.css" rel="stylesheet" type="text/css">
    <script src="./assets/jquery.min.js"></script>
    <script type="text/javascript" src="assets/corpus.js"></script>

</head>
<!-- === Header Ends === -->

<script>
    var lang_flag = 1;
</script>

<body>

<!-- === Home Section Starts === -->
<div class="section">
    <!-- === Title Starts === -->
    <div class="header">
        <!--        <div class="logo">-->
        <!--            <a href="https://decisionforce.github.io/" target="_blank">-->
        <!--                <img src="images/deciforce.png">-->
        <!--            </a>-->
        <!--        </div>-->
        <!--        <div style="padding-top: 30pt; margin: 0 50pt;" class="title" id="lang">-->
        <!--            Learning to Simulate Self-driven Particles System with Coordinated Policy Optimization-->
        <!--        </div>-->

        <!--        -->
        <!--        -->


        <table>
            <tr>
                <td>

                    <div class="logo"
                         style="
                         width: 120pt;
                         vertical-align: text-top;
                         text-align: center;
                         ">
                        <a href="https://decisionforce.github.io/" target="_blank">
                            <img src="images/deciforce.png">
                        </a>
                    </div>

                </td>
                <td>
                    <div style="padding-top: 10pt;" class="title" id="lang">
                        Learning to Simulate Self-driven Particles System with Coordinated Policy Optimization
                    </div>

                </td>
                <td>

                    <div class="logo"
                         style="
                         width: 120pt;
                         vertical-align: text-top;
                         text-align: center;
                         ">
                        <a href="https://github.com/decisionforce/metadrive" target="_blank">
                            <img style=" width: 135pt;" src="images/metadrive.png">
                        </a>
                    </div>

                </td>
            </tr>
        </table>


    </div>
    <!-- === Title Ends === -->
    <div class="author">
        <p style="text-align:center">NeurIPS 2021</p>
        <a href="https://pengzhenghao.github.io" target="_blank">Zhenghao Peng</a><sup>1</sup>,&nbsp;&nbsp;
        <a href="https://quanyili.github.io">Quanyi Li</a><sup>3</sup>,&nbsp;
<!--        <a href="#">Ka Ming Hui</a><sup>1</sup>,&nbsp;-->
        <a href="#">Chunxiao Liu</a><sup>2</sup>,&nbsp;
        <a href="https://boleizhou.github.io" target="_blank">Bolei Zhou</a><sup>1</sup>&nbsp;
    </div>
    <div class="institution">
        <div>
            <sup>1</sup>The Chinese University of Hong Kong,
            <sup>2</sup>SenseTime Research <br>
            <sup>3</sup>Centre for Perceptual and Interactive Intelligence<br>
        </div>
    </div>
    <table border="0" align="center">
        <tr>
            <td align="center" style="padding: 0pt 0 15pt 0">
                <a class="bar" href="https://decisionforce.github.io/CoPO"><b>Webpage</b></a> |
                <a class="bar" href="https://github.com/decisionforce/CoPO"><b>Code</b></a> |
                <a class="bar" href="https://youtu.be/sOw43l8lwxE"><b>Talk</b></a> |
                <a class="bar" href="copo_poster.pdf"><b>Poster</b></a> |
                <a class="bar" href="https://arxiv.org/pdf/2110.13827.pdf"><b>Paper</b></a> |
                <a class="bar" href="https://github.com/metadriverse/metadrive-benchmark/tree/main/MARL"><b>Results&Models</b></a>
            </td>
        </tr>
    </table>

</div>
<!-- === Home Section Ends === -->


<div class="section">
    <!--    <div class="title" id="lang">Demonstrative Videos</div>-->
    <div align="center">
        <table width="100%" style="margin: -20pt 0pt; text-align: center;">
            <tr>
                <td>
                    <video style="display:block; width:100%; height:auto; "
                           autoplay="autoplay" muted loop="loop" playsinline>
                        <source src="https://raw.githubusercontent.com/decisionforce/archive/master/CoPO/copo_teaser.mp4"
                                type="video/mp4"/>
                    </video>
                    <div style="top: -10%;">
                        CoPO-trained agents exhibit social behaviors.
                    </div>
                    <br>
                </td>
            </tr>
        </table>
    </div>
</div>


<!-- === Overview Section Starts === -->
<div class="section">
    <div class="title" id="lang">Coordinated Policy Optimization (CoPO)</div>
    <div class="body">
        <div class="teaser">
            <img style="width: 61.8%;"
                 src="https://raw.githubusercontent.com/decisionforce/archive/master/CoPO/copo_method.png">
        </div>
        <div class="text">
            <br>
            <p>
                We develop a novel MARL method <b>Coordinated Policy Optimization (CoPO)</b> to facilitate the bi-level
                coordination of agents to learn the controllers of the Self-driven Particles systems, especially
                traffic flows.
            </p>
            <p>
                CoPO consists of
                the Local Coordination, a mechanism to coordinate agents' objectives in neighborhood by use local
                coordination factor (LCF) to weight the individual reward and the neighborhood reward,
                and
                the Global Coordination, which uses meta-gradient to update LCF.
            </p>
            <p>
                CoPO can learn realistic crowd actions as well as safe and socially compliant driving skills.
            </p>
        </div>
    </div>
</div>


<!-- === Result Section Starts === -->
<div class="section">
    <div class="title" id="lang">Experiment Result</div>
    <div class="body">
        <table width="100%" style="margin: 0pt 0pt; text-align: center;">
            <tr>
                <td>
                    <video style="display:block; width:100%; height:auto; text-align: center;"
                           autoplay="autoplay" muted loop="loop" playsinline>
                        <source src="https://raw.githubusercontent.com/decisionforce/archive/master/CoPO/copo_env.mp4"
                                type="video/mp4"/>
                    </video>
                    <div style="top: -10%;"></div>
                    <br>
                </td>
            </tr>
        </table>
        <div class="text">
            <p>
                We develop 5 Multi-agent traffic simulation environments based on <a
                    href="http://github.com/decisionforce/metadrive">MetaDrive</a>.
            </p>
            <p>
                Compared to baselines, the proposed CoPO method achieves superior performance in success rate (ratio of
                vehicles achieving destinations),
                efficiency (frequency of successes) and safety (total number of crashes, the lower the better) as shown
                in the below figure.
            </p>
        </div>
        <div class="teaser">
            <img src="images/main_result.png">
        </div>
        <div class="text">
            The following video shows the population behaviors in Intersection environment. We use the red dots to
            indicate crashes. CoPO population is coordinated and high-performing.
        </div>
        <table width="100%" style="margin: 10pt 0pt; text-align: center;">
            <tr>
                <td>
                    <video style="display:block; width:100%; height:auto; text-align: center;"
                           autoplay="autoplay" muted loop="loop" playsinline>
                        <source src="https://raw.githubusercontent.com/decisionforce/archive/master/CoPO/copo_inter.mp4"
                                type="video/mp4"/>
                    </video>
                    <div style="top: -10%;"></div>
                    <br>
                </td>
            </tr>
        </table>
    </div>
</div>
<!-- === Result Section Ends === -->

<div class="section">
    <div class="title" id="lang">Talk</div>
    <div class="body">
        <div class="body" style="position: relative; padding-top: 50%; margin: 10pt auto; text-align: center;">
            <iframe src="https://www.youtube.com/embed/sOw43l8lwxE" frameborder=0
                    style="position: absolute; top: 2.5%; left: 2.5%; width: 95%; height: 107%;"
                    allow="accelerometer; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div>
        <div class="text" style="padding-top: 40pt;">
            Chinese version of talk can be found at <a
                href="https://www.bilibili.com/video/BV1gr4y1C7Ab?share_source=copy_web" target="_blank">bilibili</a>.
        </div>
    </div>
</div>

<!-- === Reference Section Starts === -->
<div class="section">
    <div class="bibtex">
        <div class="text">Reference</div>
    </div>

    <!--    If you find this work useful in your project, please consider to cite it through:-->
    <pre>
@article{peng2021learning,
  title={Learning to Simulate Self-Driven Particles System with Coordinated Policy Optimization},
  author={Peng, Zhenghao and Hui, Ka Ming and Liu, Chunxiao and Zhou, Bolei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
    </pre>
    <!-- Adjust the frame size based on the demo (Every project differs). -->
</div>

</body>
</html>
